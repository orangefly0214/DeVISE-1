{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By Kevin Xu\n",
    "#kevin28520@gmail.com\n",
    "\n",
    "\n",
    "#DATA:\n",
    "    #1. cifar10(binary version):https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "    #2. pratrained weights (vgg16.npy):https://mega.nz/#!YU1FWJrA!O1ywiCS2IiOlUCtCpI6HTJOMrneN-Qdv3ywQP5poecM\n",
    "    \n",
    "# TO Train and test:\n",
    "    #0. get data ready, get paths ready !!!\n",
    "    #1. run training_and_val.py and call train() in the console\n",
    "    #2. call evaluate() in the console to test\n",
    "    \n",
    "#\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import input_data\n",
    "import VGG\n",
    "import tools\n",
    "\n",
    "#\n",
    "IMG_W = 32\n",
    "IMG_H = 32\n",
    "N_CLASSES = 10\n",
    "BATCH_SIZE = 32\n",
    "learning_rate = 0.01\n",
    "MAX_STEP = 15000   # it took me about one hour to complete the training.\n",
    "IS_PRETRAIN = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#%%   Training\n",
    "def train():\n",
    "    \n",
    "    pre_trained_weights = './vgg16_pretrain/vgg16.npy'\n",
    "    data_dir = '/home/tony/Desktop/Datasets/cifar_10_batches_binary_version/'\n",
    "    train_log_dir = './logs/train/'\n",
    "    val_log_dir = './logs/val/'\n",
    "    \n",
    "    with tf.name_scope('input'):\n",
    "        tra_image_batch, tra_label_batch = input_data.read_cifar10(data_dir=data_dir,\n",
    "                                                 is_train=True,\n",
    "                                                 batch_size= BATCH_SIZE,\n",
    "                                                 shuffle=True)\n",
    "        val_image_batch, val_label_batch = input_data.read_cifar10(data_dir=data_dir,\n",
    "                                                 is_train=False,\n",
    "                                                 batch_size= BATCH_SIZE,\n",
    "                                                 shuffle=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[BATCH_SIZE, IMG_W, IMG_H, 3])\n",
    "    y_ = tf.placeholder(tf.int16, shape=[BATCH_SIZE, N_CLASSES]) \n",
    "    \n",
    "    ####find out that the use of this function of this line other time\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=True): \n",
    "        logits = VGG.VGG16N(x, N_CLASSES, IS_PRETRAIN)\n",
    "    \n",
    "    #logits = VGG.VGG16N(x, N_CLASSES, IS_PRETRAIN)\n",
    "    \n",
    "    \n",
    "    loss = tools.loss(logits, y_)\n",
    "    accuracy = tools.accuracy(logits, y_)\n",
    "    \n",
    "    my_global_step = tf.Variable(0, name='global_step', trainable=False) \n",
    "    train_op = tools.optimize(loss, learning_rate, my_global_step)   \n",
    "    \n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    summary_op = tf.summary.merge_all()   \n",
    "       \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('load the parameter file')\n",
    "    # load the parameter file, assign the parameters, skip the specific layers\n",
    "    tools.load_with_skip(pre_trained_weights, sess, ['fc6','fc7','fc8'])   \n",
    "    print('end load the parameter file')\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)    \n",
    "    tra_summary_writer = tf.summary.FileWriter(train_log_dir, sess.graph)\n",
    "    val_summary_writer = tf.summary.FileWriter(val_log_dir, sess.graph)\n",
    "    \n",
    "    \n",
    "    life_point_const = 2000\n",
    "    life_point = life_point_const\n",
    "    tmp_loss = 999999999\n",
    "    try:\n",
    "        for step in np.arange(MAX_STEP):\n",
    "            if coord.should_stop():\n",
    "                break\n",
    "            print(\"step %d\"%step)\n",
    "            tra_images,tra_labels = sess.run([tra_image_batch, tra_label_batch])\n",
    "            #print(tra_labels)\n",
    "            print(\"end load train picture\")\n",
    "            _, tra_loss, tra_acc = sess.run([train_op, loss, accuracy],\n",
    "                                            feed_dict={x:tra_images, y_:tra_labels})\n",
    "            print(\"end train\")\n",
    "            if step % 50 == 0 or (step + 1) == MAX_STEP:                 \n",
    "                print ('Step: %d, loss: %.4f, accuracy: %.4f%%' % (step, tra_loss, tra_acc))\n",
    "                summary_str = sess.run(summary_op,\n",
    "                                            feed_dict={x:tra_images, y_:tra_labels})\n",
    "                tra_summary_writer.add_summary(summary_str, step)\n",
    "            \n",
    "            \n",
    "            val_images, val_labels = sess.run([val_image_batch, val_label_batch])\n",
    "            val_loss, val_acc = sess.run([loss, accuracy],\n",
    "                                         feed_dict={x:val_images,y_:val_labels})\n",
    "            \n",
    "            if step % 200 == 0 or (step + 1) == MAX_STEP:\n",
    "#                 val_images, val_labels = sess.run([val_image_batch, val_label_batch])\n",
    "#                 val_loss, val_acc = sess.run([loss, accuracy],\n",
    "#                                              feed_dict={x:val_images,y_:val_labels})\n",
    "                print('**  Step %d, val loss = %.2f, val accuracy = %.2f%%  **' %(step, val_loss, val_acc))\n",
    "\n",
    "                summary_str = sess.run(summary_op,\n",
    "                                             feed_dict={x:val_images,y_:val_labels})\n",
    "                val_summary_writer.add_summary(summary_str, step)\n",
    "            \n",
    "            if tmp_loss > val_loss:\n",
    "                life_point = life_point_const\n",
    "                tmp_loss = val_loss\n",
    "                \n",
    "                checkpoint_path = os.path.join(train_log_dir, 'model.ckpt')\n",
    "                saver.save(sess, checkpoint_path, global_step=step)\n",
    "            else:\n",
    "                life_point = life_point -1\n",
    "                \n",
    "            if life_point < 0:\n",
    "                break\n",
    "                \n",
    "                \n",
    "            \n",
    "#             if step % 200 == 0 or (step + 1) == MAX_STEP:\n",
    "#                 val_images, val_labels = sess.run([val_image_batch, val_label_batch])\n",
    "#                 val_loss, val_acc = sess.run([loss, accuracy],\n",
    "#                                             feed_dict={x:val_images,y_:val_labels})\n",
    "#                 print('**  Step %d, val loss = %.2f, val accuracy = %.2f%%  **' %(step, val_loss, val_acc))\n",
    "\n",
    "#                 summary_str = sess.run(summary_op,\n",
    "#                                              feed_dict={x:val_images,y_:val_labels})\n",
    "#                 val_summary_writer.add_summary(summary_str, step)\n",
    "#             if step % 2000 == 0 or (step + 1) == MAX_STEP:\n",
    "#                 checkpoint_path = os.path.join(train_log_dir, 'model.ckpt')\n",
    "#                 saver.save(sess, checkpoint_path, global_step=step)\n",
    "            \n",
    "            \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training -- epoch limit reached')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        \n",
    "    coord.join(threads)\n",
    "    sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "#%%   Test the accuracy on test dataset. got about 85.69% accuracy.\n",
    "import math\n",
    "def evaluate():\n",
    "    with tf.Graph().as_default():\n",
    "        \n",
    "#        log_dir = 'C://Users//kevin//Documents//tensorflow//VGG//logsvgg//train//'\n",
    "        log_dir = './logs/train/'\n",
    "        test_dir = '/home/tony/Desktop/Datasets/cifar_10_batches_binary_version/'\n",
    "        n_test = 10000\n",
    "                \n",
    "        images, labels = input_data.read_cifar10(data_dir=test_dir,\n",
    "                                                    is_train=False,\n",
    "                                                    batch_size= BATCH_SIZE,\n",
    "                                                    shuffle=False)\n",
    "\n",
    "        logits = VGG.VGG16N(images, N_CLASSES, IS_PRETRAIN)\n",
    "        correct = tools.num_correct_prediction(logits, labels)\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            print ('########')\n",
    "#             tra_images,tra_labels = sess.run([images, labels])\n",
    "#             print (tra_labels)\n",
    "            print(\"Reading checkpoints...\")\n",
    "            ckpt = tf.train.get_checkpoint_state(log_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "                print('Loading success, global_step is %s' % global_step)\n",
    "            else:\n",
    "                print('No checkpoint file found')\n",
    "                return\n",
    "        \n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess = sess, coord = coord)\n",
    "            \n",
    "            try:\n",
    "                print('\\nEvaluating......')\n",
    "                num_step = 2 #int(math.floor(n_test / BATCH_SIZE))\n",
    "                num_sample = num_step*BATCH_SIZE\n",
    "                step = 0\n",
    "                total_correct = 0\n",
    "                while step < num_step and not coord.should_stop():\n",
    "                    tra_images, tra_labels, batch_correct = sess.run([images, labels, correct])\n",
    "                    total_correct += np.sum(batch_correct)\n",
    "                    step += 1\n",
    "                    #print (tra_labels)\n",
    "                print('Total testing samples: %d' %num_sample)\n",
    "                print('Total correct predictions: %d' %total_correct)\n",
    "                print('Average accuracy: %.2f%%' %(100*total_correct/num_sample))\n",
    "            except Exception as e:\n",
    "                coord.request_stop(e)\n",
    "            finally:\n",
    "                coord.request_stop()\n",
    "                coord.join(threads)\n",
    "                \n",
    "#%%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10)\n",
      "(32, 10)\n",
      "load the parameter file\n",
      "end load the parameter file\n",
      "step 0\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "print(t0)\n",
    "train()\n",
    "t1 = time.time()\n",
    "print(t1-t0)\n",
    "print(t1)\n",
    "evaluate()\n",
    "t0 = time.time()\n",
    "print(t0-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
